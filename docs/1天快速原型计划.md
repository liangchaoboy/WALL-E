# 1天快速原型开发计划
# WALL-E 语音导航 MVP

---

## 📑 文档信息

| 项目 | 内容 |
|------|------|
| **项目名称** | WALL-E 快速原型 |
| **版本** | v0.1 (Prototype) |
| **开发时间** | 1 天 (8 小时) |
| **目标** | 语音导航基础功能可用 |
| **开发方式** | 极客快速开发,能跑就行 |

---

## 🎯 核心理念

**快速 > 完美**  
**能用 > 优雅**  
**原型 > 产品**

不追求完美架构,不追求最佳实践,目标是最快时间内跑通核心功能!

---

## 💡 极简技术方案

### 放弃的复杂方案
❌ Swift + Go + gRPC + MCP 多技术栈  
❌ Porcupine 唤醒词引擎  
❌ 完整的系统托盘应用  
❌ 数据库、历史记录  
❌ 完善的错误处理  

### 极简方案
✅ **纯 Python 一个文件搞定**  
✅ 用系统自带的语音识别  
✅ 直接调用 OpenAI API  
✅ 用 `webbrowser` 打开地图  
✅ 命令行运行,够用就行  

---

## 🚀 1天时间规划

### 上午 (4小时): 核心功能

#### 任务 1: 环境搭建 (30分钟)
```bash
# 创建虚拟环境
python3 -m venv venv
source venv/bin/activate

# 安装依赖
pip install openai speechrecognition pyaudio
```

#### 任务 2: 语音识别 (1小时)
```python
# voice_nav.py
import speech_recognition as sr

def listen():
    """监听麦克风,返回识别的文本"""
    recognizer = sr.Recognizer()
    with sr.Microphone() as source:
        print("请说话...")
        audio = recognizer.listen(source)
    
    try:
        text = recognizer.recognize_google(audio, language='zh-CN')
        print(f"识别结果: {text}")
        return text
    except:
        print("识别失败")
        return None
```

**验收**: 运行后能识别语音并打印文本

#### 任务 3: AI 理解 - 支持第三方 API (1.5小时)
```python
import openai
import os

def understand_intent(text):
    """用第三方大模型 API 理解用户意图"""
    # 支持自定义 base_url、API_KEY、model
    api_key = os.getenv("API_KEY", "YOUR_API_KEY")
    base_url = os.getenv("BASE_URL", "https://api.openai.com/v1")  # 默认 OpenAI
    model = os.getenv("MODEL", "gpt-3.5-turbo")  # 默认模型
    
    client = openai.OpenAI(
        api_key=api_key,
        base_url=base_url
    )
    
    response = client.chat.completions.create(
        model=model,
        messages=[
            {"role": "system", "content": """你是地图导航助手。
用户说导航需求,你提取起点和终点。
返回 JSON: {"action": "navigate", "from": "起点", "to": "终点"}
如果无法理解,返回 {"action": "unknown"}"""},
            {"role": "user", "content": text}
        ]
    )
    
    import json
    result = json.loads(response.choices[0].message.content)
    return result
```

**配置说明**:
- `BASE_URL`: 第三方 API 接口地址 (如: `https://api.deepseek.com/v1`)
- `API_KEY`: 对应的 API 密钥
- `MODEL`: 使用的模型名称 (如: `deepseek-chat`, `gpt-4`, 等)

**验收**: 
1. 配置第三方 API 接口
2. 输入"从上海到北京"能返回正确的 JSON
3. 支持切换不同的大模型服务商

#### 任务 4: 打开地图 (1小时)
```python
import webbrowser

def navigate(origin, destination):
    """打开百度地图导航"""
    url = f"https://map.baidu.com/?from={origin}&to={destination}&output=html"
    webbrowser.open(url)
    print(f"已打开地图: {origin} → {destination}")
```

**验收**: 调用函数能在浏览器打开地图

---

### 下午 (4小时): 集成与优化

#### 任务 5: 主循环集成 (1小时)
```python
def main():
    print("WALL-E 语音导航启动!")
    print("说'退出'可以结束程序")
    
    while True:
        # 1. 监听语音
        text = listen()
        if not text:
            continue
        
        if "退出" in text:
            print("再见!")
            break
        
        # 2. 理解意图
        intent = understand_intent(text)
        
        # 3. 执行操作
        if intent.get("action") == "navigate":
            origin = intent.get("from", "当前位置")
            destination = intent.get("to")
            if destination:
                navigate(origin, destination)
        else:
            print("抱歉,我没听懂")

if __name__ == "__main__":
    main()
```

**验收**: 完整流程跑通 - 说话 → 识别 → 理解 → 打开地图

#### 任务 6: 基础优化 (1.5小时)
- 添加环境变量读取 API Key
- 添加简单的错误提示
- 添加重试机制
- 优化提示信息

```python
import os
from dotenv import load_dotenv

load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

def understand_intent(text):
    try:
        # 支持第三方 API 配置
        api_key = os.getenv("API_KEY")
        base_url = os.getenv("BASE_URL", "https://api.openai.com/v1")
        model = os.getenv("MODEL", "gpt-3.5-turbo")
        
        client = openai.OpenAI(api_key=api_key, base_url=base_url)
        response = client.chat.completions.create(model=model, ...)
        return result
    except Exception as e:
        print(f"AI理解失败: {e}")
        return {"action": "unknown"}
```

#### 任务 7: 快速测试 (1小时)
- 测试各种导航指令
- 测试错误场景
- 记录已知问题

#### 任务 8: 简单文档 (30分钟)
- 写 README.md 说明如何运行
- 列出依赖和环境要求
- 说明已知限制

---

## 📝 最终交付

### 文件结构
```
walle-prototype/
├── voice_nav.py          # 主程序 (200行左右)
├── requirements.txt      # 依赖列表
├── .env.example         # API Key 示例
└── README.md            # 使用说明
```

### 功能清单
- ✅ 语音输入 (使用 Google 语音识别)
- ✅ AI 理解 (使用 ChatGPT)
- ✅ 地图导航 (打开百度地图)
- ✅ 命令行交互
- ✅ 基本错误处理

### 已知限制
- ⚠️ 需要联网
- ⚠️ 需要第三方大模型 API (支持 OpenAI、DeepSeek 等兼容接口)
- ⚠️ 需要麦克风权限
- ⚠️ 仅支持导航功能
- ⚠️ 没有唤醒词,需要手动启动
- ⚠️ 没有 GUI,纯命令行
- ⚠️ 识别准确率依赖网络质量

---

## 🎯 验收标准

### 必须能做到
1. ✅ 运行 `python voice_nav.py` 启动程序
2. ✅ 对着麦克风说"从上海到北京"
3. ✅ 程序识别语音,调用 AI 理解
4. ✅ 自动打开浏览器显示地图路线
5. ✅ 整个流程 < 5 秒完成

### Demo 场景
```
$ python voice_nav.py
WALL-E 语音导航启动!
说'退出'可以结束程序

请说话...
识别结果: 从上海七牛云到虹桥机场
AI理解: 导航 - 上海七牛云 → 虹桥机场
已打开地图: 上海七牛云 → 虹桥机场

请说话...
识别结果: 退出
再见!
```

---

## 💻 完整代码示例

```python
#!/usr/bin/env python3
"""
WALL-E 语音导航原型
1天快速开发版本 - 能跑就行!
"""

import os
import json
import webbrowser
import speech_recognition as sr
from openai import OpenAI
from dotenv import load_dotenv

# 加载配置
load_dotenv()
client = OpenAI(
    api_key=os.getenv("API_KEY"),
    base_url=os.getenv("BASE_URL", "https://api.openai.com/v1")
)

def listen():
    """监听语音并转文字"""
    recognizer = sr.Recognizer()
    
    with sr.Microphone() as source:
        print("\n🎤 请说话...")
        try:
            audio = recognizer.listen(source, timeout=5)
            text = recognizer.recognize_google(audio, language='zh-CN')
            print(f"📝 识别: {text}")
            return text
        except sr.WaitTimeoutError:
            print("⏰ 没听到声音")
            return None
        except sr.UnknownValueError:
            print("❌ 无法识别")
            return None
        except Exception as e:
            print(f"❌ 错误: {e}")
            return None

def understand(text):
    """AI 理解用户意图"""
    try:
        response = client.chat.completions.create(
            model=os.getenv("MODEL", "gpt-3.5-turbo"),
            messages=[
                {
                    "role": "system",
                    "content": """你是导航助手。用户说导航需求,提取起点终点。
返回 JSON:
- 导航: {"action":"nav","from":"起点","to":"终点"}  
- 其他: {"action":"unknown"}"""
                },
                {"role": "user", "content": text}
            ],
            temperature=0
        )
        
        result = json.loads(response.choices[0].message.content)
        print(f"🤖 AI: {result}")
        return result
        
    except Exception as e:
        print(f"❌ AI失败: {e}")
        return {"action": "unknown"}

def navigate(origin, destination):
    """打开百度地图"""
    url = f"https://map.baidu.com/?from={origin}&to={destination}"
    webbrowser.open(url)
    print(f"🗺️  已打开: {origin} → {destination}")

def main():
    """主程序"""
    print("=" * 50)
    print("🤖 WALL-E 语音导航原型")
    print("说话即可导航,说'退出'结束")
    print("=" * 50)
    
    while True:
        # 监听
        text = listen()
        if not text:
            continue
        
        # 退出
        if "退出" in text or "结束" in text:
            print("👋 再见!")
            break
        
        # 理解
        intent = understand(text)
        
        # 执行
        if intent.get("action") == "nav":
            navigate(
                intent.get("from", "当前位置"),
                intent.get("to", "")
            )
        else:
            print("❓ 没听懂,请说导航指令")

if __name__ == "__main__":
    main()
```

---

## 📦 依赖文件

### requirements.txt
```
openai>=1.0.0
SpeechRecognition>=3.10.0
PyAudio>=0.2.13
python-dotenv>=1.0.0
```

### .env.example
```
# 第三方大模型 API 配置
API_KEY=sk-your-api-key-here
BASE_URL=https://api.openai.com/v1
MODEL=gpt-3.5-turbo

# 示例: 使用 DeepSeek
# API_KEY=sk-your-deepseek-key
# BASE_URL=https://api.deepseek.com/v1
# MODEL=deepseek-chat
```

### README.md
```markdown
# WALL-E 语音导航原型

1天快速开发版本,仅实现核心功能。

## 快速开始

1. 安装依赖:
   ```bash
   pip install -r requirements.txt
   ```

2. 配置 API Key:
   ```bash
   cp .env.example .env
   # 编辑 .env 填入你的 API Key、BASE_URL 和 MODEL
   # 支持 OpenAI、DeepSeek 等任意兼容 OpenAI 接口的服务
   ```

3. 运行:
   ```bash
   python voice_nav.py
   ```

4. 使用:
   - 对着麦克风说导航指令
   - 例如: "从上海到北京"
   - 说"退出"结束程序

## 系统要求

- Python 3.8+
- 麦克风
- 联网
- macOS/Linux/Windows

## 已知问题

- 需要第三方大模型 API (有成本)
- 语音识别需要网络
- 没有唤醒词
- 只能导航,不支持其他功能
```

---

## 🎉 总结

### 为什么能1天完成?

1. **技术选择简单**
   - Python 单文件
   - 现成的库 (SpeechRecognition, OpenAI)
   - 不造轮子

2. **功能极简**
   - 只做语音导航
   - 不做 UI
   - 不做数据库
   - 不做复杂架构

3. **质量要求低**
   - 能跑就行
   - 不追求健壮性
   - 不追求性能
   - 不追求美观

### 后续演进路径

这个原型验证了可行性后,可以:
1. 用 Electron 做 GUI
2. 添加唤醒词
3. 支持更多操作
4. 优化语音识别
5. 添加本地模型

但那些都是后话,**先把原型跑起来最重要!**

---

## ⚡ 开发节奏

| 时间 | 任务 | 输出 |
|------|------|------|
| 09:00-09:30 | 环境搭建 | Python 环境 + 依赖 |
| 09:30-10:30 | 语音识别 | 能识别语音转文字 |
| 10:30-12:00 | AI 理解 | ChatGPT 能解析意图 |
| 12:00-13:00 | 午休 | - |
| 13:00-14:00 | 地图导航 | 能打开浏览器地图 |
| 14:00-15:00 | 集成调试 | 完整流程跑通 |
| 15:00-16:30 | 优化测试 | 修 Bug,加错误处理 |
| 16:30-17:00 | 文档 | README + 使用说明 |

**总计: 7 小时**

预留 1 小时 buffer 处理意外问题。

---

**原型开发的精髓就是: 快速验证想法,不要被完美主义困住!** 🚀
